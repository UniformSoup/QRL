{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c8565d7-2922-4d57-a726-40a2edcbb210",
   "metadata": {},
   "source": [
    "# <center>A Classical Actor Critic Agent</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1773330-9590-4ac5-9908-1e13b9d45fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras import Input, layers, Model\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "import gym\n",
    "\n",
    "from utilities import train_agent, render, animation\n",
    "from rl_algorithms import ActorCritic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed05494-587a-4096-9999-dc58fc3f5b51",
   "metadata": {},
   "source": [
    "<center>Create Gym Environment</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90e53ef-4f3d-46ac-bd8f-84e65356c9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d5846d-356a-4c5c-9139-c19b4a00149c",
   "metadata": {},
   "source": [
    "<center>Define Model Architecture</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ac091d-2441-453d-811d-c83b24744faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 7\n",
    "\n",
    "inputs = Input(shape=env.observation_space.shape[0], dtype=tf.dtypes.float32, name='Input')\n",
    "\n",
    "dense = layers.Dense(128, activation='relu')(inputs)\n",
    "\n",
    "policy_logits = layers.Dense(2, activation='relu')(dense)\n",
    "value = layers.Dense(1, activation='relu', name=\"Value\")(dense)\n",
    "policy = layers.Softmax(name=\"Policy\")(policy_logits)\n",
    "\n",
    "actor = Model(inputs=[inputs], outputs=policy, name=\"Actor\")\n",
    "critic = Model(inputs=[inputs], outputs=value,  name=\"Critic\")\n",
    "model = Model(inputs=[inputs], outputs=[policy, value], name=\"Actor-Critic\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a264d0c1-507d-47f8-b10b-afeea3652ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, to_file=\"/tmp/model.png\", show_shapes=True, dpi=70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890a2b87-2d70-42d4-aec4-7b5007408d9c",
   "metadata": {},
   "source": [
    "<center>Train Model</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2a3210-9882-49ea-886e-0e17f8014fae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "agent = ActorCritic(actor, critic, learning_rate=0.005, discount_factor=0.9)\n",
    "\n",
    "def shaped_reward(reward, observation):\n",
    "    position, pos_vel, angle, angle_vel = observation\n",
    "    #return (1 - tf.abs(angle))\n",
    "    return 1 - 0.5 * tf.abs(position) - 0.5 * tf.abs(angle)\n",
    "\n",
    "state_bounds = np.array([2.4, 2.5, 0.21, 2.5]).astype(np.float32)\n",
    "    \n",
    "agent, total_rewards, episode_lengths = train_agent(env, agent, shaped_reward,\n",
    "                                                    500, 5000, state_bounds,\n",
    "                                                    (475, 100), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca7cc77-fd08-496e-a740-fa6969fe4690",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(8, 8))\n",
    "\n",
    "def smooth(s, alpha=0.2):\n",
    "    averaging_length = int(len(s)*alpha)\n",
    "    s = np.pad(s, (averaging_length//2, averaging_length//2), mode='edge')\n",
    "    return np.convolve(s, np.ones(averaging_length)/averaging_length, mode='valid')\n",
    "\n",
    "labels = ['Total Reward', 'Average Reward', 'Cumulative Reward', 'Episode Length']\n",
    "data = [total_rewards, np.array(total_rewards) / episode_lengths, np.cumsum(total_rewards), episode_lengths]\n",
    "\n",
    "for ax, label, data in zip(axes.flat, labels, data):\n",
    "    ax.set_xlabel('Episode')\n",
    "    ax.set_ylabel(label)\n",
    "    ax.plot(data)\n",
    "    if label != 'Cumulative Reward': ax.plot(smooth(data), '--')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917cb8c2-0ced-4903-a59c-b6479441d323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvirtualdisplay import *\n",
    "vdisp = Display(visible=0, size=(500, 500)).start()\n",
    "\n",
    "def action_fn(env, observation):\n",
    "    observation = observation / state_bounds\n",
    "    prediction = agent.actor(observation[None, :])\n",
    "    action = tf.random.categorical(tf.math.log(prediction), num_samples=1)\n",
    "    return tf.squeeze(action).numpy()\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "frames = render(env, action_fn, 500)\n",
    "env.close()\n",
    "\n",
    "HTML(animation(frames, len(frames)/24e-3).to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f04eff-2f52-4557-aff4-1ae92b13dba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, os\n",
    "\n",
    "timestamp = time.strftime(\"%Y.%m.%d-%H.%M\")\n",
    "os.mkdir(f'./AC{timestamp}')\n",
    "print(f'./AC{timestamp}')\n",
    "\n",
    "results = {\"Total Reward\":total_rewards, \"Episode Length\": episode_lengths}\n",
    "np.save(f'./AC{timestamp}/results.npy', results)\n",
    "agent.actor.save(f'./AC{timestamp}/actor.keras')\n",
    "agent.critic.save(f'./AC{timestamp}/critic.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b492571-9962-4450-8c6c-7326026aac37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
